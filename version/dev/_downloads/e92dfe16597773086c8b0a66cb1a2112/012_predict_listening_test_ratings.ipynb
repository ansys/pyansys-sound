{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Predict listening test ratings\n\nThis example shows how to predict the mean ratings of automotive HVAC sounds based on\npsychoacoustic indicators, using the data from a listening test conducted with Ansys Sound - Jury\nListening Test (JLT).\n\nHere, we demonstrate how to build an objective indicator to help predict automotive HVAC sound\nratings, on the basis of 4 psychoacoustic indicators that are typically used for such sounds:\n\n- Loudness (ISO 532-1),\n- Sharpness (DIN 45692),\n- Fluctuation strength (Sontacchi method),\n- Tonality (ECMA 418-2).\n\nThe sound ratings used in this example were obtained from a listening test designed with Ansys\nSound JLT. In this test, 29 participants evaluated 20 automotive HVAC sounds. This example uses the\ndata obtained when exporting, in JLT, the analyzed results to a CSV file. With a standard\ninstallation of JLT, the corresponding listening test project should be located here:\n`C:/Users/Public/Documents/Ansys/Acoustics/JLT/CE - Automotive HVAC`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set up analysis\nSetting up the analysis consists of loading Ansys libraries, connecting to the DPF server, and\ndownloading the necessary data files.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Load standard libraries.\nfrom math import sqrt\nimport os\n\nfrom ansys.dpf.core import Field\nimport matplotlib.pyplot as plt\nfrom sklearn import linear_model\n\n# Load Ansys libraries.\nfrom ansys.sound.core.examples_helpers import (\n    download_all_carHVAC_wav,\n    download_HVAC_test_wav,\n    download_JLT_CE_data_csv,\n)\nfrom ansys.sound.core.psychoacoustics import (\n    FluctuationStrength,\n    LoudnessISO532_1_Stationary,\n    SharpnessDIN45692,\n    TonalityECMA418_2,\n)\nfrom ansys.sound.core.server_helpers import connect_to_or_start_server\nfrom ansys.sound.core.signal_utilities import LoadWav\nfrom ansys.sound.core.signal_utilities.crop_signal import CropSignal\n\n# Connect to a remote DPF server or start a local DPF server.\nmy_server, my_license_context = connect_to_or_start_server(use_license_context=True)\n\n# Download the necessary files for this example.\nmodel_wav_files_path = download_all_carHVAC_wav()\nJLT_ratings_path = download_JLT_CE_data_csv()\ntest_wav_file_path = download_HVAC_test_wav()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define indicator computation function\nHere we define a function that calculates the 4 psychoacoustic indicators of interest (listed at\nthe beginning of the example), given an input sound signal as a DPF field.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def compute_indicators(signal: Field) -> list:\n    \"\"\"Compute psychoacoustic indicators for a given sound signal.\n\n    Parameters\n    ----------\n    signal : Field\n        Sound signal to analyze.\n\n    Returns\n    -------\n    list\n        List of psychoacoustic indicator values: loudness level in phon, sharpness in acum,\n        fluctuation strength in vacil, and tonality in tuHMS.\n    \"\"\"\n    # Loudness level (ISO 532-1)\n    indicator = LoudnessISO532_1_Stationary(signal=signal)\n    indicator.process()\n    LN = indicator.get_loudness_level_phon()\n\n    # Sharpness (DIN 45692)\n    indicator = SharpnessDIN45692(signal=signal)\n    indicator.process()\n    S = indicator.get_sharpness()\n\n    # Fluctuation strength (Sontacchi method)\n    indicator = FluctuationStrength(signal=signal)\n    indicator.process()\n    FS = indicator.get_fluctuation_strength()\n\n    # Tonality (ECMA 418-2)\n    indicator = TonalityECMA418_2(signal=signal, field_type=\"Free\", edition=\"3rd\")\n    indicator.process()\n    T = indicator.get_tonality()\n\n    return [LN, S, FS, T]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define prediction function\nHere we define a function that predicts the rating for an automotive HVAC sound signal, given a\nset of regression coefficients. The function computes 4 relevant psychoacoustic indicators for\nautomotive HVAC sounds, and then applies the regression formula to obtain the predicted rating:\n\n\\begin{align}rating = a_0 + a_1 \\cdot LN + a_2 \\cdot S + a_3 \\cdot FS + a_4 \\cdot T\\end{align}\n\nwhere $a_0$ is the intercept and $a_1$, $a_2$, $a_3$, and $a_4$ are\nthe coefficients of the model, and $LN$, $S$, $FS$, and $T$ are the\nloudness level, sharpness, fluctuation strength, and tonality, respectively.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def apply_prediction_formula(signal: Field, coefficients: list = None) -> float:\n    \"\"\"Apply the regression formula to predict the rating of a sound signal.\n\n    Parameters\n    ----------\n    signal : Field\n        Sound signal to evaluate.\n\n    coefficients : list, default: None.\n        List of regression coefficients (including the intercept): a0, a1, a2, a3, and a4. If None,\n        the coefficients are [1, 0, 0, 0, 0].\n\n    Returns\n    -------\n    float\n        Predicted rating of the input sound signal.\n    \"\"\"\n    if coefficients is None:\n        coefficients = [1, 0, 0, 0, 0]\n    elif not (isinstance(coefficients, list)) or len(coefficients) != 5:\n        raise TypeError(\"coefficients must be a list of 5 elements.\")\n\n    # Compute the psychoacoustic indicators for the sound file.\n    indicators = compute_indicators(signal)\n\n    # Apply the formula to compute the rating.\n    return (\n        coefficients[0]\n        + coefficients[1] * indicators[0]\n        + coefficients[2] * indicators[1]\n        + coefficients[3] * indicators[2]\n        + coefficients[4] * indicators[3]\n    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Read the Ansys Sound JLT data\nRead the CSV file produced with Ansys Sound JLT. This file contains descriptive statistics of the\nsound ratings obtained during the listening test conduction. Most notably, it contains the\nrating of each sound averaged over the test participants.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Initialize lists to store file names and ratings.\nfilenames = []\nratings = []\n\n# Print the file content for information.\nwith open(JLT_ratings_path, encoding=\"utf-8-sig\") as f:\n    print(f.read())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Extract HVAC sound file names and mean ratings from the CSV file.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "with open(JLT_ratings_path, encoding=\"utf-8-sig\") as f:\n    lines = f.readlines()\n    lines = lines[7:]  # Skip the first 7 lines (general info, and table header).\n\n    # Store file names and mean ratings (first and second columns).\n    for line in lines:\n        row = line.split(\";\")\n        filenames.append(row[0])\n        ratings.append(float(row[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calculate the psychoacoustic indicators\nCompute the psychoacoustic indicators for each sound file. The following indicators are computed:\n\n- Loudness (ISO 532-1),\n- Sharpness (DIN 45692),\n- Fluctuation strength (Sontacchi method),\n- Tonality (ECMA 418-2).\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>This computation step may be long, as some indicators (fluctuation strength, and tonality) are\n   quite heavy to compute. Note also that, although the sounds of the test are stereo (binaural\n   recordings) and 5 seconds long, we are using the first second of the left channel only. You\n   get similar results if you use the right channel or the average of the two, and the full\n   signal duration.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Initialize a list to store the indicators for each file. The list will contain sublists, each\n# sublist containing the values of the selected indicators for each sound.\nindicators = []\n\n# Process each sound file one by one.\nfor file_name in filenames:\n    print(f\"Calculating indicators for file: {file_name} ...\")\n    wav_file_path = os.path.join(model_wav_files_path, file_name + \".wav\")\n\n    # Load the sound file.\n    wav_loader = LoadWav(wav_file_path)\n    wav_loader.process()\n\n    # Keep the first channel only.\n    signal = wav_loader.get_output()[0]\n\n    # Keep the first second of signal only.\n    cropper = CropSignal(signal=signal, start_time=0.0, end_time=1.0)\n    cropper.process()\n    signal = cropper.get_output()\n\n    # Compute and append the indicator values for the current sound to the list.\n    indicators.append(compute_indicators(signal))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calculate the multiple linear regression\nUse package :mod:`sklearn` (https://scikit-learn.org/) to create a multiple linear\nregression model, to predict the ratings based on the computed psychoacoustic indicators.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Create and compute the model.\nregression = linear_model.LinearRegression()\nregression.fit(indicators, ratings)\n\n# Compute the predicted ratings using the regression model.\nratings_hat = regression.predict(indicators)\n\n# Display the model coefficients and the correlation coefficient.\nprint(f\"Linear regression model coefficients: {regression.coef_}\")\nprint(f\"Correlation coefficient: {sqrt(regression.score(indicators, ratings)):.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the predicted ratings against the actual ratings.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.plot([0, 100], [0, 100], \"k--\")\nplt.scatter(ratings_hat, ratings)\nplt.xlabel(\"Predicted ratings\")\nplt.ylabel(\"Actual ratings\")\nplt.title(\"Predicted vs Actual ratings\")\nplt.xlim(0, 100)\nplt.ylim(0, 100)\nplt.grid()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The correlation coefficient (0.983) is very close to 1, and the points in the plot are\nwell aligned. This shows that the rating prediction model is quite accurate for the sounds of\nthe listening test.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Use the regression coefficients for prediction\nUse the model coefficients to estimate the rating of a new sound file. Using the model\ncoefficients consists of computing the indicators and applying the formula:\n\n\\begin{align}rating = a_0 + a_1 \\cdot LN + a_2 \\cdot S + a_3 \\cdot FS + a_4 \\cdot T\\end{align}\n\nwhere $a_0$ is the intercept and $a_1$, $a_2$, $a_3$, and $a_4$ are\nthe coefficients of the model, and $LN$, $S$, $FS$, and $T$ are the\nloudness level, sharpness, fluctuation strength, and tonality, respectively.\n\nThe coefficients of the model are stored in the regression object, and can be accessed using the\n``coef_`` attribute. The intercept is stored in the ``intercept_`` attribute of the regression\nobject.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Load the sound file for which to predict the rating.\nwav_loader = LoadWav(test_wav_file_path)\nwav_loader.process()\n\n# Keep the first channel only.\nsignal = wav_loader.get_output()[0]\n\n# Apply the regression formula to predict the rating of the sound file.\n# Note: the intercept (offset) must be added to the coefficients list.\ncoefficients = [regression.intercept_] + list(regression.coef_)\nrating_hat = apply_prediction_formula(signal, coefficients)\n\nprint(\n    f\"\\nPredicted rating (0-100) for file {os.path.split(test_wav_file_path)[-1]}: {rating_hat:.2f}\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This predicted rating (28.52) tells us that the sound is not very pleasant in comparison with the\nother sounds of the listening test, and that it would have probably ranked poorly, had it been\nincluded during the test conduction.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}